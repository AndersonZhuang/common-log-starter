package com.diit.example.service;

import com.diit.example.entity.BusinessLogEntity;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.stereotype.Service;

import jakarta.annotation.PostConstruct;
import jakarta.annotation.PreDestroy;
import java.time.LocalDateTime;
import java.util.Properties;
import java.util.UUID;

/**
 * ç›´æ¥KafkaæœåŠ¡
 * ä¸ä¾èµ–Springçš„KafkaTemplateï¼Œç›´æ¥ä½¿ç”¨Kafkaå®¢æˆ·ç«¯
 * 
 * @author diit
 */
@Slf4j
@Service
@ConditionalOnProperty(prefix = "diit.log.kafka", name = "enabled", havingValue = "true")
public class DirectKafkaService {
    
    private KafkaProducer<String, String> producer;
    private final ObjectMapper objectMapper = new ObjectMapper()
            .registerModule(new JavaTimeModule());
    
    @PostConstruct
    public void init() {
        try {
            // åˆ›å»ºKafkaç”Ÿäº§è€…é…ç½®
            Properties props = new Properties();
            props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
            props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
            props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
            props.put(ProducerConfig.ACKS_CONFIG, "all");
            props.put(ProducerConfig.RETRIES_CONFIG, 3);
            props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384);
            props.put(ProducerConfig.LINGER_MS_CONFIG, 1);
            props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432);
            props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
            
            // åˆ›å»ºç”Ÿäº§è€…
            producer = new KafkaProducer<>(props);
            log.info("âœ… ç›´æ¥Kafkaç”Ÿäº§è€…åˆå§‹åŒ–æˆåŠŸ");
            
        } catch (Exception e) {
            log.error("âŒ ç›´æ¥Kafkaç”Ÿäº§è€…åˆå§‹åŒ–å¤±è´¥", e);
        }
    }
    
    @PreDestroy
    public void cleanup() {
        if (producer != null) {
            producer.close();
            log.info("ğŸ”„ Kafkaç”Ÿäº§è€…å·²å…³é—­");
        }
    }
    
    /**
     * å‘é€è‡ªå®šä¹‰æ—¥å¿—åˆ°Kafka
     */
    public void sendCustomLog(String message) {
        try {
            if (producer == null) {
                log.warn("âš ï¸ Kafkaç”Ÿäº§è€…æœªåˆå§‹åŒ–");
                return;
            }
            
            // åˆ›å»ºä¸šåŠ¡æ—¥å¿—å®ä½“ï¼ˆåŒ…å«æ‰€æœ‰è‡ªå®šä¹‰å­—æ®µï¼‰
            BusinessLogEntity businessLog = new BusinessLogEntity();
            
            // è®¾ç½®åŸºç¡€å­—æ®µï¼ˆç»§æ‰¿è‡ªBaseLogEntityï¼‰
            businessLog.setId(UUID.randomUUID().toString());
            businessLog.setTimestamp(LocalDateTime.now());
            businessLog.setContent("è‡ªå®šä¹‰æ—¥å¿—ï¼š" + message);
            businessLog.setLevel(org.springframework.boot.logging.LogLevel.INFO);
            
            // è®¾ç½®ä¸šåŠ¡ç‰¹å®šå­—æ®µï¼ˆBusinessLogEntityçš„æ ¸å¿ƒå­—æ®µï¼‰
            businessLog.setBusinessType("è®¢å•å¤„ç†");
            businessLog.setDepartment("æŠ€æœ¯éƒ¨");
            businessLog.setProject("ç”µå•†ç³»ç»Ÿ");
            
            // åºåˆ—åŒ–ä¸ºJSON
            String jsonMessage = objectMapper.writeValueAsString(businessLog);
            
            // ç¡®å®šTopicåç§°
            String topic = "log_custom_messages";
            String key = "custom-" + System.currentTimeMillis();
            
            // å‘é€åˆ°Kafka
            ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, jsonMessage);
            
            producer.send(record, (metadata, exception) -> {
                if (exception != null) {
                    log.error("âŒ è‡ªå®šä¹‰æ—¥å¿—å‘é€å¤±è´¥ - Topic: {}, Key: {}, Error: {}", 
                             topic, key, exception.getMessage());
                } else {
                    log.info("âœ… è‡ªå®šä¹‰æ—¥å¿—å‘é€æˆåŠŸ - Topic: {}, Key: {}, Partition: {}, Offset: {}", 
                            topic, key, metadata.partition(), metadata.offset());
                }
            });
            
            log.info("ğŸš€ è‡ªå®šä¹‰æ—¥å¿—å·²å‘é€åˆ°Kafka:");
            log.info("   Topic: {}", topic);
            log.info("   Key: {}", key);
            log.info("   Message: {}", jsonMessage);
            
        } catch (Exception e) {
            log.error("å‘é€è‡ªå®šä¹‰æ—¥å¿—å¤±è´¥", e);
            throw new RuntimeException("Failed to send custom log to Kafka", e);
        }
    }
}
